---
title: "Predicting Methylation Age In Mouse"
output: html_document
# params:
#    covFolder: NULL
#    RdataFile: NULL

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Sequencing Data

The first step to get to the methylation age prediction of the ages in mouse is the mapping of the sequencing data to mouse genome.
For this trim galore (for QC) and Bismark (for the actual mapping) is used for mapping the data to the latest mouse genome build (GRCm38).
The genome reference is available:
ftp://ftp.ensembl.org/pub/release-87/fasta/mus_musculus/dna/
Software is available:
https://github.com/FelixKrueger/Bismark
https://github.com/FelixKrueger/TrimGalore


The used settings are shown below:

`trim_galore --rrbs *fastq.gz
 
bismark --genome GRCm38 -1 R1_trimmed.fq.gz -2 R2_trimmed.fq.gz
 
bismark_methylation_extractor --gzip --bedGraph *bam`

From the Bismark mapping we take the ".cov"" / ".cov.gz"" files which can be used in the code below to calculate the methylation age.
Please be aware that the read data has to be merged before attempting the age prediction.

## Predicting methylation age in mouse
After alignment we take the ".cov" file from the mapping. Please make a folder containing only the methylation files you want to use during the prediction.
Files found in the folder:


```{r readData, echo=F}
load(params$RdataFile)
source(params$sourceFunctions)
require(preprocessCore)
library(readr)
library(DMwR2)

toProcess <- list.files(params$covFolder,pattern = ".cov") #list of bismarked files
print(toProcess)

filesToProcess <- list()
for(file in toProcess){
  tmp <- read.delim(paste(params$covFolder,file,sep=""),as.is = T, header = F)
  rownames(tmp)<- paste(tmp[,1], tmp[,2],sep=":")
  tmp <- tmp[,4:ncol(tmp)]
  tmp[,2] <- tmp[,2]+tmp[,3]
  tmp[,1] <- tmp[,1]/100
  tmp <- tmp[which(tmp[,2]>=params$ReadDepth),c(1:2)] 
  tmp <- tmp[which(rownames(tmp) %in% sitesForPrediction),] # trim new samples: remove sites which were not in 'the 18 thousand sites which were present in the original samples'
  filesToProcess[[file]] <- tmp
}
rm(tmp, covFol, functionFile, ImputationTrainingMatrix, RdataF)

```



```{r impute, echo=F, warning=F}

# import data which is used for imputation
TrainingMatrix <- read.delim(params$ImputationTrainingMatrix, row.names=1, sep="\t",as.is=T)


# merge new samples
Merge <- filesToProcess[[1]]
colnames(Merge) <- c( 'meth1', 'reads1')

if (length(filesToProcess) == 1) { 
  colnames(Merge) <- c(names(filesToProcess)[1], 'reads') 
}

if (length(filesToProcess) > 1) {
  for (i in 2:length(filesToProcess)) {
    colnames(filesToProcess[[i]]) <- c(paste0('meth', i), paste0('reads', i))
    Merge <- merge(Merge, filesToProcess[[i]], by="row.names", all = T, nomatch = NA) 
    rownames(Merge) <- Merge[,1] 
    Merge <- Merge[,2:ncol(Merge)]
  }
  Merge <- Merge[, seq(1, dim(Merge)[2],2)]
  colnames(Merge) <- names(filesToProcess)
}


# merge new samples with Stubbs training data (TrainingMatrix)
MergeAll <- merge(Merge, TrainingMatrix, by="row.names", all = T, nomatch = NA)
rownames(MergeAll) <- MergeAll[,1] # site as rowname
MergeAll <- MergeAll[,2:ncol(MergeAll)]

if (length(filesToProcess) == 1) { 
  MergeAll <- MergeAll[-2]
}

# kNN imputation (k=5)
MergeImp <- MergeAll

for (i in seq_len(ncol(Merge))) { # overwrites MergeAll results with imputed values (in case Imputation is possible)
  try(expr = {
    MergeImp[,i] <- knnImputation(t(MergeAll[,i]),
                                            k = 5,
                                            scale = F,
                                            meth = "weighAvg",
                                            distData = t(TrainingMatrix)) },
    silent = T)
}


rm(filesToProcess)
filesToProcess <- list()
for (i in 1:length(toProcess)){
  imp_file <- cbind(MergeImp[,i], rep(NA, times=length(MergeImp[,i]))) # read info is NA
  colnames(imp_file) <- c(colnames(MergeImp)[i], 'reads')
  rownames(imp_file) <- rownames(MergeImp)
  filesToProcess[[i]] <- imp_file
}
names(filesToProcess) <- toProcess
```

As a first step, we are going to impute the methylation levels for all the 18 thousand CpG sites which were present in the original samples but are missing in the input samples. The imputation is carried out via k nearest neighbour (kNN) approach with k = 5 and based on all input samples as well as all original samples, which were used to build the Stubbs2017 clock.

The following number of CpG sites was imputated to obtain a methylation level:
```{r print_NA_number, echo=F}
if (length(filesToProcess) == 1) {
  print(sum(is.na(MergeAll[,1])))
} else {
  print(colSums(is.na(MergeAll[,1:length(toProcess)])))
}
```
This corresponds to the following percentage of imputed methylation levels out of all 18 thousand methylation levels:
```{r print_NA_percent, echo=F}

for (i in 1:length(toProcess)) {
  cat(colnames(MergeAll)[i], '\n', sum(is.na(MergeAll[,i]))/ length(sitesForPrediction) *100, '%', '\n')
}
```


If all methylation values could be imputed, we can use the original quantile normalization to normalize the samples. If these sites are not present in a sample this sample is taken along for direct prediction without quantile normalization. The next step is to identify the samples which have all clock sites. The clock sites are selected and standardized using the original site mean and site standard deviation. As a last step we take the methylation values and perform the prediction and plot and write the methylation age predictions

```{r processData, echo=F}
  predictedAges <- list()
  qnPerformed <- NULL
  for(i in 1:length(filesToProcess)){
    
    if ( sum(is.na(MergeAll[,i]))/length(sitesForPrediction) == 1) { 
      print(paste("QN was not possible (as not a single CpG site was covered) by sample: ",names(filesToProcess)[i]))
      qnPerformed <- c(qnPerformed,F)
    } else if(dim(filesToProcess[[i]])[1]==length(sitesForPrediction)){
      filesToProcess[[i]][,1] <- normalize.quantiles.use.target(matrix(filesToProcess[[i]][,1],ncol=1), target = qnTarget)
      print(paste("QN was performed for sample: ",names(filesToProcess)[i]))
      qnPerformed <- c(qnPerformed,T)
    } else {
      print(paste("QN was not possible for sample: ",names(filesToProcess)[i]))
      qnPerformed <- c(qnPerformed,F)
    }
    
    filesToProcess[[i]] <- filesToProcess[[i]][which(rownames(filesToProcess[[i]]) %in% rownames(betas)),]
    filesToProcess[[i]] <- filesToProcess[[i]][rownames(betas),]
  
    if ( sum(is.na(MergeAll[,i]))/length(sitesForPrediction) == 1 ) { ### # NA if no CpG site covered
      print(paste("Unable to predict age for sample: ",names(filesToProcess)[i]))
      predictedAges[names(filesToProcess)[i]] <- NA
    } else if (dim(filesToProcess[[i]])[1]==length(rownames(betas))){
      
      filesToProcess[[i]] <- filesToProcess[[i]][order(rownames(filesToProcess[[i]])),]
      filesToProcess[[i]]<- sweep(x =filesToProcess[[i]], 1, rowMean, "-" )
      filesToProcess[[i]] <- sweep(x =filesToProcess[[i]], 1, rowStDev, "/" )
      
      sitesTrainingData <- as.data.frame(filesToProcess[[i]][,1])
      betaScoreSample <- sitesTrainingData*betas
      betaScoreSample <- apply(betaScoreSample,2, sum)
       
      predictedAges[names(filesToProcess)[i]] <- revertAge(betaScoreSample)
      print(paste("Age was predicted for sample: ",names(filesToProcess)[i]))
    } else {
      print(paste("Unable to predict age for sample: ",names(filesToProcess)[i]))
      predictedAges[names(filesToProcess)[i]] <- NA
    }
  }
```

The final predicted ages are:

```{r finalStage, echo=F}
  for(i in 1:length(predictedAges)){
    if(qnPerformed[i]){
      print(paste("Predicted age for sample ",names(filesToProcess)[i],": ",round(predictedAges[[i]],digits = 1), sep=""))
    } else {
      print(paste("Predicted age for sample ",names(filesToProcess)[i],": ",round(predictedAges[[i]],digits = 1), " *", sep=""))
    }
    
  }
```

Age predictions which are marked with a star, are not quantile normalized before running the age prediction, prediction might be off.
